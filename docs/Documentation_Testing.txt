TESTING DOCUMENTATION

// ALGORITHM FOR TESTING LLM
1. We use a dataset using natural language, describing the diagnosis and the symptoms.
We used 1011 data points from the dataset from this source:
https://www.kaggle.com/datasets/niyarrbarman/symptom2disease/discussion/402748
2. We pulled the data out of a csv file using readCSV.js and save as dataset files, dividing them into three files.
(so that the LLM does not get overwhelmed with a large dataset)
3. Use symptom phrases to generate diagnosis with LLM.
4. Compare LLM diagnosis with diagnosis from the dataset.
5. Save the result in a correctAnswers Array (true/false)
6. Count the amount of correct and wrong answers, give it out in terminal

// INSTALLATION STEPS
1. Run the following command to install csv for reading the test csv data file.
npm install csv

// RUNNING THE TEST PROGRAM
1. Go into the 'testing' folder and run:
node datasetTest

// KNOWN BUGS
None

// DATASET1 (333 entries)
Amount of correct answers
60
Amount of wrong answers
273

// DATASET 2 (317 entries) 
Amount of correct answers
14
Amount of wrong answers
303

// DATASET3 (361 entries)
Amount of correct answers
28
Amount of wrong answers
333

// OVERALL AMOUNT OF CORRECT AND WRONG ANSWERS
Correct	Wrong	Percentage
60	    273	  22%
14	    303	  5%
28	    333	  8%
102	    909	  11%

// EVALUATION
1. This test helped us to run the application a lot more times than we would be able if we did things manually.
As such we were able to figure out bugs in extractSymptoms function which lead to JSON.parse not giving out an error
and not saving the generated symptoms. 
2. We see a rather low correctness percentage, which may be due to weakness of Ollama as an LLM model or 
 errors in our testing process, as written in more details below.

// WEAKNESSES OF THE EVALUATION
1. Source of data is an open source file with symptoms and disease data. It is not a source of a medical
institution, as such it may have weaknesses in accuracy of symptoms and its chosen diagnoses.
However, it saved the data in natural language in the way a patient may disclose their symptoms.
A cursory check of the symptoms and diagnoses did show accurate depictions 
(as far as we as non-professionals can judge).
https://www.kaggle.com/datasets/niyarrbarman/symptom2disease
2. The strength of our program is that the LLM can ask additional questions. This test does not use
additional answers, as programming for LLM to generate additional answers was out of time scope
and could lead to additional errors (as the answers given by the LLM could also be faulty and not
simulate the real user experience).
3. The algorithm is checking the correct result using an exact match. This may falsify the results,
as the same diagnosis could be made by the LLM and used in the file, while using different terms.

// POSSIBILITIES FOR EXPANSION
1. More data sources and higher quality data sources could improve the result.
2. We could simulate answers by using randomized Yes/No responses. It could be possible to simulate
answers using as data basis all the symptom texts for a certain diagnosis
3. It may be better to ask the LLM to compare the two diagnosis and to check how similar they are.
A sliding scale evaluation (Correct, Possibly Correct, Wrong) could be more accurate, as some
diagnoses may not be made with a single symptoms sentence description, as such several diagnoses 
could apply.